import numpy as np

"""
This version is generated by aistudio from paper->latex, then generated into python functions by chatgpt

"""

class PROControlModel:
    def __init__(self, num_stimuli,
                num_responses,
                num_outcomes,
                num_conjunctions,
                num_delay_units,
                alphaRO=0.012,
                alphaTD=0.1,
                gamma=0.0,
                rho=1.764,
                phi=2.246,
                psi=0.724,
                beta=1.038,
                sigma=0.25,
                response_threshold=0.313):

        self.num_stimuli = num_stimuli
        self.num_responses = num_responses
        self.num_outcomes = num_outcomes
        self.num_conjunctions = num_conjunctions
        self.num_delay_units = num_delay_units

        self.alphaRO = alphaRO  # Baseline learning rate
        self.alphaTD = alphaTD      # Learning rate for TD model
        self.gamma = gamma # Temporal discount factor and decay for delay line
        self.rho = rho      # Input scaling factor
        self.phi = phi      # Control signal scaling factor for C
        self.psi = psi      # Control signal scaling factor for S
        self.beta = beta      # Rate coding scaling factor
        self.sigma = sigma    # Noise variance in control units
        self.response_threshold = response_threshold  # Response threshold

        # Initialize weights
        self.W_S = np.random.rand(self.num_stimuli, self.num_conjunctions) # Stimulus to conjunctions
        self.W_C = np.random.rand(self.num_stimuli, self.num_responses) # Stimulus to responses (fixed)
        self.W_F = np.zeros((self.num_conjunctions, self.num_responses)) # Conjunctions to responses (top-down)
        self.W_I = -np.eye(self.num_responses) * 0.5  # Lateral inhibition weights (can be modified for Simulations 5)
        self.U = np.random.rand(self.num_delay_units, self.num_outcomes)  # Delay to outcome prediction


    # Equation (1): Prediction of the activation of response-outcome conjunction
    def predict_activation(self, D_t, W_S):
        """
        Parameters:
        D_t: array of activations for stimulus units at time t
        W_S: matrix of weights connecting stimulus units to response-outcome conjunctions
        
        Returns:
        S_t: array of predictions of response-outcome conjunctions at time t
        """
        return np.dot(D_t, W_S)

    # Equation (2): Weight update rule
    def update_weight(self, W_S, A_t, O_t, S_t, G_t, D_t):
        """
        Parameters:
        W_S: matrix of weights at time t
        A_t: learning rate for each conjunction at time t
        O_t: actual outcome occurrence at time t
        S_t: predicted activation at time t
        G_t: gating signal (1 if event occurred, 0 otherwise)
        D_t: activation of stimulus units at time t
        
        Returns:
        Updated weights W_S for the next time step
        """
        error = (O_t - S_t) * G_t
        return W_S + A_t[:, np.newaxis] * error[:, np.newaxis] * D_t[np.newaxis, :]

    # Equation (3): Dynamic learning rate
    def dynamic_learning_rate(self, alpha, omega_P, omega_N):
        """
        Parameters:
        alpha: baseline learning rate
        omega_P: positive surprise
        omega_N: negative surprise
        
        Returns:
        A_t: dynamic learning rate
        """
        return alpha / (1 + omega_P + omega_N)

    # Equation (4): Temporal difference error
    def temporal_difference_error(self, r_t, V_t, V_t1, gamma):
        """
        Parameters:
        r_t: reward signal at time t
        V_t: predicted value at time t
        V_t1: predicted value at time t+1
        gamma: temporal discount factor
        
        Returns:
        delta_t: temporal difference error
        """
        return r_t + gamma * V_t1 - V_t

    # Equation (6): Predicted value calculation
    def predicted_value(self, X_t, U):
        """
        Parameters:
        X_t: activation of delay line for each stimulus
        U: weights connecting delay line to predictions
        
        Returns:
        V_t: predicted value at time t
        """
        return np.dot(X_t, U)

    def eligibility_trace(self, X_t):
        """
        Parameters:
        X_t: activation of delay line for each stimulus
        e_trace: eligibility trace
        """
        self.e_trace = X_t * 0.95 * self.e_trace
        return self.e_trace

    # Equation (7): Weight update rule for U
    def update_U_weights(self, U, alphaTD, delta_t, X_t):
        """
        Parameters:
        U: weights at time t
        alpha: learning rate
        delta_t: temporal difference error
        X_t: delay line activations
        
        Returns:
        Updated weights U for the next time step
        """
        return U + alphaTD * delta_t * self.eligibility_trace(X_t)

    # Equation (8): Delay line update
    def update_delay_line(self, X_t, gamma):
        """
        Parameters:
        X_t: delay line activations at time t
        gamma: decay factor
        
        Returns:
        Updated delay line X for the next time step
        """
        return gamma * X_t

    # Equation (9): Response unit activation dynamics
    def response_unit_dynamics(self, C_t, beta, dt, E_t, I_t, sigma):
        """
        Parameters:
        C_t: response unit activation at time t
        beta: scaling factor
        dt: time step
        E_t: excitatory input at time t
        I_t: inhibitory input at time t
        sigma: noise variance
        
        Returns:
        Updated activation of response unit C at time t+1
        """
        noise = np.random.normal(0, sigma)
        return C_t + dt * (beta * E_t * (1 - C_t) - (C_t + 0.05) * I_t) + noise

    # Equation (10): Excitatory input calculation
    def excitatory_input(self, rho, D_t, W_C):
        """
        Parameters:
        rho: scaling factor
        D_t: task stimuli activations
        W_C: weights connecting stimuli to response unit
        
        Returns:
        E_t: excitatory input to response unit
        """
        return rho * np.dot(D_t, W_C)

    # Equation (11): Inhibitory input calculation
    def inhibitory_input(self, C_t, W_I, S_t, W_F, phi, psi):
        """
        Parameters:
        C_t: response unit activations
        W_I: mutual inhibition weights
        S_t: predicted response-outcome activations
        W_F: top-down control weights
        phi: scaling factor for C-based inhibition
        psi: scaling factor for S-based inhibition
        
        Returns:
        I_t: inhibitory input to response unit
        """
        inhibition_from_C = phi * np.dot(C_t, W_I)
        inhibition_from_S = psi * np.dot(S_t, W_F)
        return inhibition_from_C + inhibition_from_S

    # Equation (12): Update top-down control weights
    def update_top_down_weights(self, W_F, C_t, T_t, O_t, G_t, Y_t):
        """
        Parameters:
        W_F: top-down control weights at time t
        C_t: response unit activations
        T_t: thresholded activations
        O_t: observed outcome
        G_t: gating signal
        Y_t: affective evaluation of outcome
        
        Returns:
        Updated weights W_F for the next time step
        """
        return W_F + 0.01 * np.outer(C_t * T_t * O_t * G_t, Y_t)

    # Equation (13): Positive surprise
    def positive_surprise(self, O, V):
        """
        Parameters:
        O: observed outcome activations
        V: predicted outcome activations
        
        Returns:
        omega_P: positive surprise signal
        """
        return np.sum(np.maximum(O - V, 0))

    # Equation (14): Negative surprise
    def negative_surprise(self, V, O):
        """
        Parameters:
        V: predicted outcome activations
        O: observed outcome activations
        
        Returns:
        omega_N: negative surprise signal
        """
        return np.sum(np.maximum(V - O, 0))

    # Page 3 - Alternative definition for negative surprise
    def alternative_negative_surprise(self, expected, actual):
        """
        Parameters:
        expected: array of expected outcomes
        actual: array of actual outcomes
        
        Returns:
        omega_N: alternative negative surprise signal
        """
        return np.sum(np.maximum(expected - actual, 0)) / 2

    def step(self, D_t, previous_response, previous_outcome):
        # Controller: Predict response-outcome conjunction activation (Eq. 1)
        S_t = self.predict_activation(D_t, self.W_S)

        # Critic: Predict value (Eq. 6) based on delay line (X_t)
        X_t = np.zeros(self.num_delay_units)  # Initialize delay line
        V_t = self.predicted_value(X_t, self.U)

        # Actor: Compute excitatory/inhibitory inputs and response unit dynamics
        E_t = self.excitatory_input(self.rho, D_t, self.W_C)
        I_t = self.inhibitory_input(np.zeros(self.num_responses), self.W_I, S_t, self.W_F, self.phi, self.psi)
        C_t = np.zeros(self.num_responses)
        C_t = self.response_unit_dynamics(C_t, self.beta, 0.01, E_t, I_t, self.sigma)

        # Response selection based on threshold
        response = np.argmax(C_t) if np.max(C_t) >= self.response_threshold else -1

        outcome = self.get_outcome(response)
        print(f"Response: {response}, Outcome: {outcome}")
        # Critic: Calculate positive and negative surprise (Eq. 13, 14)
        omega_N = self.negative_surprise(V_t, outcome)
        omega_P = self.positive_surprise(outcome, V_t)
        
        # Dynamic learning rate (Eq. 3)
        A_t = self.dynamic_learning_rate(self.alphaRO, omega_P, omega_N)
        # Update weights for controller (Eq. 2)
        G_t = 1  # Define gating signal as per task
        self.W_S = self.update_weight(self.W_S, A_t, outcome, S_t, G_t, D_t)

        # Critic: Update U using temporal difference error (Eq. 7)
        delta_t = self.temporal_difference_error(outcome, V_t, V_t, self.gamma)
        self.U = self.update_U_weights(self.U, self.alphaTD, delta_t, X_t)
        
        # Update X_t for delay line for the next trial (Eq. 8)
        X_t = self.update_delay_line(X_t, self.gamma)
        
        # Top-down control update (Eq. 12)
        Y_t = self.get_affective_evaluation(outcome)
        T_t = np.where(C_t > self.response_threshold, 1, 0)
        self.W_F = self.update_top_down_weights(self.W_F, C_t, T_t, outcome, G_t, Y_t)

        return response, outcome, omega_N, omega_P, S_t, V_t

    def get_outcome(self, response):
        """Replace with your task's outcome logic."""
        # Example: random outcome for demonstration
        if response == 0:  # Example condition
            return np.random.choice([0, 1], p=[0.8, 0.2]) # Example probabilities
        elif response == 1:  # Example condition
            return np.random.choice([0, 1], p=[0.2, 0.8]) # Example probabilities
        else:  # No response
            return -1 

    def get_affective_evaluation(self, outcome):
        """Replace with affective evaluation based on outcome"""
        if outcome == 0: # Example for error
            return 1
        elif outcome == 1: # Example for correct
            return -0.1
        else: # No outcome (e.g. no response made)
            return 0


# Example usage (replace parameters with your experiment setup):
num_stimuli = 4  # Example
num_responses = 2  # Example
num_outcomes = 2  # Example
num_conjunctions = num_outcomes * num_responses # Example
num_delay_units = 10 # Example (adjust based on your needs)

model = PROControlModel(num_stimuli, num_responses, num_outcomes, num_conjunctions, num_delay_units)

# Example simulation loop:
num_trials = 1000
previous_response, previous_outcome = -1, -1
for trial in range(num_trials):
    D_t = np.zeros(model.num_stimuli)
    D_t[0] = 1  # Activate stimulus for example
    response, outcome, omega_N, omega_P, S_t, V_t = model.step(D_t, previous_response, previous_outcome)
    print(f"Trial {trial+1}: Response: {response}, Outcome: {outcome}, Negative Surprise: {omega_N}")
    previous_response, previous_outcome = response, outcome