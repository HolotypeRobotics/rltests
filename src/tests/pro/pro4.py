import numpy as np
import matplotlib.pyplot as plt

"""
This version was generated by claude from pro3.py by telling it to clean it up.
"""

class PROControlModel:
    def __init__(self,
                n_stimuli,
                n_responses,
                n_outcomes,
                n_timesteps=100,
                dt=0.1,
                alpha=0.1,
                beta=0.1,
                gamma=0.95,
                lambda_decay=0.95,
                psi=0.1,
                phi=0.1,
                rho=0.1,
                noise_sigma=0.1,
                response_threshold=0.1):
        # Basic parameters
        self.dt = dt
        self.gamma = gamma
        self.alpha = alpha
        self.beta = beta
        self.n_timesteps = n_timesteps
        self.lambda_decay = lambda_decay
        self.noise_sigma = noise_sigma
        self.response_threshold = response_threshold
        
        # Scaling parameters
        self.psi = psi
        self.phi = phi
        self.rho = rho

        # Dimensions
        self.n_stimuli = n_stimuli
        self.n_responses = n_responses
        self.n_outcomes = n_outcomes
        
        # Initialize weights
        self.W_S = np.abs(np.random.normal(0.1, 0.05, (n_outcomes, n_stimuli)))  # Stimulus-Outcome weights
        self.W_C = np.ones((n_responses, n_stimuli))  # Stimulus-Response weights
        self.W_F = -np.abs(np.random.normal(0, 0.1, (n_responses, n_outcomes)))  # Response-Outcome weights
        self.W_I = -np.eye(n_responses)  # Response inhibition weights
        
        # Initialize temporal prediction weights and eligibility traces
        self.U = np.zeros((n_outcomes, n_stimuli, n_timesteps))
        self.eligibility_trace = np.zeros_like(self.U)
        
        # Surprise weights
        self.W_omega_N = np.random.normal(0, 0.1, (n_responses, n_outcomes))
        
        # State variables
        self.C = np.zeros(n_responses)  # Response activations
        self.omega_P = np.zeros(n_outcomes)  # Positive surprise
        self.omega_N = np.zeros(n_outcomes)  # Negative surprise
        self.TD_error = np.zeros(n_outcomes)  # TD error
        self.V = np.zeros(n_outcomes)  # Value predictions

    def compute_outcome_prediction(self, stimuli):
        """Compute immediate outcome predictions"""
        return np.dot(self.W_S, stimuli)

    def compute_temporal_prediction(self, stimuli):
        """Compute temporal predictions"""
        if stimuli.ndim == 1:
            stimuli = stimuli[:, None]
        self.V = np.sum(np.sum(self.U * stimuli[None, :, :], axis=1), axis=1)
        return self.V

    def compute_surprise(self, predicted, actual):
        """Compute positive and negative surprise"""
        self.omega_P = np.maximum(0, actual - predicted)
        self.omega_N = np.maximum(0, predicted - actual)
        return self.omega_P, self.omega_N

    def compute_response_activation(self, stimuli, current_response, outcome_prediction):
        """Compute response activation combining excitation and inhibition"""
        # Excitation
        direct = np.dot(stimuli, self.W_C.T)
        proactive = -np.sum(np.maximum(0, np.dot(self.W_F, outcome_prediction)))
        reactive = -np.sum(np.maximum(0, self.W_omega_N), axis=1)
        excitation = self.rho * (direct + proactive + reactive)
        
        # Inhibition
        direct_inhib = self.psi * np.dot(current_response, self.W_I)
        proactive_inhib = np.sum(np.maximum(0, np.dot(self.W_F, outcome_prediction)))
        reactive_inhib = np.sum(np.maximum(0, self.W_omega_N), axis=1)
        inhibition = direct_inhib + self.phi * (proactive_inhib + reactive_inhib)
        
        # Update response activation
        noise = np.random.normal(0, self.noise_sigma, self.n_responses)
        delta_C = self.beta * self.dt * (excitation * (1 - current_response) - 
                                       (current_response + 0.05) * (inhibition + 1) + noise)
        self.C = np.clip(current_response + delta_C, 0, 1)
        return self.C

    def update_weights(self, stimuli, response, outcomes, next_stimuli=None):
        """Update all weights based on trial outcome"""
        # Update outcome predictions
        S = self.compute_outcome_prediction(stimuli)
        self.omega_P, self.omega_N = self.compute_surprise(S, outcomes)
        
        # Update outcome weights
        delta = self.alpha * (outcomes - S)
        self.W_S += np.outer(delta, stimuli)
        
        # Update reactive control
        outcome_valence = 1.0 if np.any(outcomes > 0) else -0.5
        executed_response = (response > self.response_threshold).astype(float)
        self.W_omega_N = 0.25 * (self.W_omega_N + outcome_valence * 
                                np.outer(executed_response, self.omega_N))
        self.W_omega_N = np.clip(self.W_omega_N, -1, 1)
        
        # Update proactive control
        if np.any(executed_response > self.response_threshold):
            self.W_F += 0.01 * np.outer(executed_response, outcomes) * outcome_valence
        
        # Update temporal predictions if next state is available
        if next_stimuli is not None:
            V_t = self.compute_temporal_prediction(stimuli)
            V_tp1 = self.compute_temporal_prediction(next_stimuli)
            r_t = 1.0 if np.any(outcomes > 0) else -0.5
            self.TD_error = r_t + self.gamma * V_tp1 - V_t
            
            # Update eligibility traces and temporal weights
            if stimuli.ndim == 1:
                stimuli = stimuli[:, None]
            for i in range(self.n_outcomes):
                for j in range(self.n_stimuli):
                    if stimuli[j, 0] > 0:
                        self.eligibility_trace[i, j, :] = np.roll(self.eligibility_trace[i, j, :], 1)
                        self.eligibility_trace[i, j, 0] = stimuli[j, 0]
                        self.U += self.alpha * self.TD_error[i] * self.eligibility_trace

def create_change_signal_task(n_trials=100, change_prob=0.3):
    """Create a change signal task"""
    stimuli = np.zeros((n_trials, 2))
    correct_responses = np.zeros((n_trials, 2))
    
    stimuli[:, 0] = 1  # Go signal
    change_trials = (np.random.random(n_trials) < change_prob)
    stimuli[change_trials, 1] = 1  # Change signal
    
    correct_responses[~change_trials, 0] = 1  # Go response
    correct_responses[change_trials, 1] = 1   # Change response
    
    return stimuli, correct_responses

def simulate_trial(model, stimulus, max_steps=100):
    """Simulate a single trial"""
    model.C = np.zeros(model.n_responses)
    S = model.compute_outcome_prediction(stimulus)
    
    for step in range(max_steps):
        response = model.compute_response_activation(stimulus, model.C, S)
        if np.any(response > model.response_threshold):
            return response, step * model.dt
    
    return model.C, max_steps * model.dt

def run_simulation(n_trials=200):
    """Run full simulation"""
    # Initialize model and task
    model = PROControlModel(
        n_stimuli=2, n_responses=2, n_outcomes=4,
        dt=0.05, alpha=0.073, beta=15.0,
        noise_sigma=0.002, response_threshold=0.34,
        psi=0.95, phi=1.0, rho=0.5
    )
    
    stimuli, correct_responses = create_change_signal_task(n_trials)
    
    # Recording arrays
    accuracy = np.zeros(n_trials)
    rts = np.zeros(n_trials)
    
    # Run trials
    for trial in range(n_trials):
        response, rt = simulate_trial(model, stimuli[trial])
        response_made = response > model.response_threshold
        accuracy[trial] = np.array_equal(response_made, correct_responses[trial])
        rts[trial] = rt
        
        # Create outcome vector
        outcome = np.zeros(model.n_outcomes)
        if response_made[0]:  # Go response
            outcome[0] = float(accuracy[trial])  # Go correct
            outcome[1] = float(not accuracy[trial])  # Go error
        elif response_made[1]:  # Change response
            outcome[2] = float(accuracy[trial])  # Change correct
            outcome[3] = float(not accuracy[trial])  # Change error
            
        # Update model
        next_stimulus = stimuli[trial + 1] if trial < n_trials - 1 else None
        model.update_weights(stimuli[trial], response, outcome, next_stimulus)
    
    return accuracy, rts

def plot_results(accuracy, rts):
    """Plot simulation results"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
    
    # Plot accuracy
    window = 20
    acc_smooth = np.convolve(accuracy, np.ones(window)/window, mode='valid')
    ax1.plot(acc_smooth)
    ax1.set_title('Running Average Accuracy')
    ax1.set_ylabel('Accuracy')
    
    # Plot RT distribution
    ax2.hist(rts, bins=20)
    ax2.set_title('Response Time Distribution')
    ax2.set_xlabel('Response Time (s)')
    ax2.set_ylabel('Count')
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    np.random.seed(42)
    accuracy, rts = run_simulation()
    plot_results(accuracy, rts)
    print(f"Mean Accuracy: {np.mean(accuracy):.3f}")
    print(f"Mean RT: {np.mean(rts):.3f}s")